{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling using Latent Dirichlet Allocation\n",
    "\n",
    "## What is Topic Modeling\n",
    "\n",
    "Topic modeling is the process of identifying patterns in text data that corresponds to a topic.\n",
    "\n",
    "## What if the text contains multiple topic\n",
    "\n",
    "If the text contains multiple topics, this technique can be used to identify and separate those themes within the input text. We do this to uncover hidden thematic structure in the given sets of documents.\n",
    "\n",
    "\n",
    "## Is this a Supervised/Unsupervised Learning?\n",
    "\n",
    "Topic modeling algorithms does not need any labeled data. It is like unsupervised learning where it will identify the patterns on its own. \n",
    "\n",
    "## Latent Dirichlet Allocation\n",
    "\n",
    "A topic modeling technique where the underlying intuition is that a given piece of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from gensim import models, corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load input data\n",
    "def load_data(input_file):\n",
    "    data = []\n",
    "    with open(input_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            data.append(line[:-1])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Processor function for tokenizing, removing stop words and stemming\n",
    "def process(input_text):\n",
    "    # Create a regular expression tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    # Create a snowball stemmer\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    \n",
    "    # Get the list of stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    # Tokenize the input string\n",
    "    tokens = tokenizer.tokenize(input_text.lower())\n",
    "    \n",
    "    # Remove the stop words\n",
    "    tokens = [x for x in tokens if not x in stop_words]\n",
    "    \n",
    "    # Perform stemming on the tokenized words\n",
    "    tokens_stemmed = [stemmer.stem(x) for x in tokens]\n",
    "    \n",
    "    return tokens_stemmed   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. The Roman empire expanded very rapidly and it was the biggest empire in the world for a long time.\n",
      "\n",
      "1. An algebraic structure is a set with one or more finitary operations defined on it that satisfies a list of axioms.\n",
      "\n",
      "2. Renaissance started as a cultural movement in Italy in the Late Medieval period and later spread to the rest of Europe.\n",
      "\n",
      "3. The line of demarcation between prehistoric and historical times is crossed when people cease to live only in the present.\n",
      "\n",
      "4. Mathematicians seek out patterns and use them to formulate new conjectures.  \n",
      "\n",
      "5. A notational symbol that represents a number is called a numeral in mathematics. \n",
      "\n",
      "6. The process of extracting the underlying essence of a mathematical concept is called abstraction.\n",
      "\n",
      "7. Historically, people have frequently waged wars against each other in order to expand their empires.\n",
      "\n",
      "8. Ancient history indicates that various outside influences have helped formulate the culture and traditions of Eastern Europe.\n",
      "\n",
      "9. Mappings between sets which preserve structures are of special interest in many fields of mathematics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load input data\n",
    "data = load_data('data.txt')\n",
    "for i, line in enumerate(data):\n",
    "    print('{}. {}\\n'.format(i, line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['roman', 'empir', 'expand', 'rapid', 'biggest', 'empir', 'world', 'long', 'time'], ['algebra', 'structur', 'set', 'one', 'finitari', 'oper', 'defin', 'satisfi', 'list', 'axiom'], ['renaiss', 'start', 'cultur', 'movement', 'itali', 'late', 'mediev', 'period', 'later', 'spread', 'rest', 'europ'], ['line', 'demarc', 'prehistor', 'histor', 'time', 'cross', 'peopl', 'ceas', 'live', 'present'], ['mathematician', 'seek', 'pattern', 'use', 'formul', 'new', 'conjectur'], ['notat', 'symbol', 'repres', 'number', 'call', 'numer', 'mathemat'], ['process', 'extract', 'under', 'essenc', 'mathemat', 'concept', 'call', 'abstract'], ['histor', 'peopl', 'frequent', 'wage', 'war', 'order', 'expand', 'empir'], ['ancient', 'histori', 'indic', 'various', 'outsid', 'influenc', 'help', 'formul', 'cultur', 'tradit', 'eastern', 'europ'], ['map', 'set', 'preserv', 'structur', 'special', 'interest', 'mani', 'field', 'mathemat']]\n"
     ]
    }
   ],
   "source": [
    "# Create a list for sentence tokens\n",
    "tokens = [process(x) for x in data]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(78 unique tokens: ['roman', 'empir', 'expand', 'rapid', 'biggest']...)\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary based on the sentence tokens\n",
    "dict_tokens = corpora.Dictionary(tokens)\n",
    "print(dict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1)], [(18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1)], [(7, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1)], [(39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1)], [(46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1)], [(50, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1)], [(1, 1), (2, 1), (33, 1), (35, 1), (59, 1), (60, 1), (61, 1), (62, 1)], [(20, 1), (29, 1), (43, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1)], [(9, 1), (10, 1), (52, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create a document-term matrix\n",
    "doc_term_mat = [dict_tokens.doc2bow(token) for token in tokens]\n",
    "print(doc_term_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the number of topics for the LDA model\n",
    "num_topics = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate the LDA model\n",
    "ldamodel = models.ldamodel.LdaModel(doc_term_mat, num_topics=num_topics, id2word=dict_tokens, passes=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topc 10 contributing words to each topic:\n",
      "\n",
      "Topic: 0\n",
      "\"mathemat\" => 5.5%\n",
      "\"call\" => 3.9%\n",
      "\"structur\" => 2.4%\n",
      "\"set\" => 2.4%\n",
      "\"map\" => 2.4%\n",
      "\"field\" => 2.4%\n",
      "\"interest\" => 2.4%\n",
      "\"preserv\" => 2.4%\n",
      "\"special\" => 2.4%\n",
      "\"mani\" => 2.4%\n",
      "\n",
      "Topic: 1\n",
      "\"empir\" => 3.3%\n",
      "\"cultur\" => 2.3%\n",
      "\"europ\" => 2.3%\n",
      "\"time\" => 2.3%\n",
      "\"peopl\" => 2.3%\n",
      "\"histor\" => 2.3%\n",
      "\"expand\" => 2.3%\n",
      "\"formul\" => 2.3%\n",
      "\"movement\" => 1.4%\n",
      "\"itali\" => 1.4%\n"
     ]
    }
   ],
   "source": [
    "num_words = 10\n",
    "print('\\nTopc {} contributing words to each topic:'.format(num_words))\n",
    "for item in ldamodel.print_topics(num_topics=num_topics, num_words=num_words):\n",
    "    print('\\nTopic:', item[0])\n",
    "    \n",
    "    # Print the contributing words along with their relative contributions\n",
    "    list_of_strings = item[1].split(' + ')\n",
    "    for text in list_of_strings:\n",
    "        weight = text.split('*')[0]\n",
    "        word = text.split('*')[1]\n",
    "        print('{} => {}%'.format(word, round(float(weight) * 100, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
