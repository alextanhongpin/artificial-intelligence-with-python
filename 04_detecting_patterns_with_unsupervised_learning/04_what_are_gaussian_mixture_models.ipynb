{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are Gaussian Mixture Models\n",
    "\n",
    "A Mixture Model is a type of probability density model where we assume that the data is governed by a number of component distributions. If these distributions are Gaussian, then the model becomes a Gaussian Mixture Model. These component distributions are combined in order to provide a multi-modal density function, which becomes a mixture model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GaussianMixture' object has no attribute '_get_covars'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-83304d2e0cd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Extract the eigenvalues and eigenvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0meigenvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_covars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Normalize the first eigenvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GaussianMixture' object has no attribute '_get_covars'"
     ]
    }
   ],
   "source": [
    "# WARNING: Not working\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Split dataset into training and testing (80/20 split)\n",
    "indices = StratifiedKFold(iris.target, n_folds=5)\n",
    "\n",
    "# Take the first fold\n",
    "train_index, test_index = next(iter(indices))\n",
    "\n",
    "# Extract training data and labels\n",
    "X_train = iris.data[train_index]\n",
    "y_train = iris.target[train_index]\n",
    "\n",
    "# Extract testing data and labels\n",
    "X_test = iris.data[test_index]\n",
    "y_test = iris.target[test_index]\n",
    "\n",
    "# Extract the number of classes\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# Build GMM\n",
    "classifier = GaussianMixture(n_components=num_classes, covariance_type='full', init_params='random')\n",
    "\n",
    "# Initialize the GMM Means\n",
    "classifier.means_ = np.array([X_train[y_train == i].mean(axis=0) for i in range(num_classes)])\n",
    "\n",
    "# Train the GMM classifier\n",
    "classifier.fit(X_train)\n",
    "\n",
    "# Draw boundaries\n",
    "plt.figure()\n",
    "colors = 'bgr'\n",
    "for i, color in enumerate(colors):\n",
    "    # Extract the eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(classifier._get_covars()[i][:2, :2])\n",
    "    \n",
    "    # Normalize the first eigenvector\n",
    "    norm_vec = eigenvectors[0] / np.linalg.norm(eigenvectors[0])\n",
    "    \n",
    "    # Extract the angle of tilt\n",
    "    angle = np.arctan2(norm_vec[1], norm_vec[0])\n",
    "    angle = 180 * angle / np.pi\n",
    "    \n",
    "    # Scaling factor to magnify the ellipses\n",
    "    # (random values chosen to suit our needs)\n",
    "    scaling_factor = 8\n",
    "    eigenvalues *= scaling_factor\n",
    "    \n",
    "    # Draw the ellipses\n",
    "    ellipse = patches.Ellipse(classifier_means_[i, :2], \n",
    "                              eigenvalues[0], \n",
    "                              eigenvalues[1], \n",
    "                              180 + angle, \n",
    "                              color=color)\n",
    "    axis_handle = plt.subplot(1, 1, 1)\n",
    "    ellipse.set_clip_box(axis_handle.bbox)\n",
    "    ellipse.set_alpha(0.6)\n",
    "    axis_handle.add_artist(ellipse)\n",
    "    \n",
    "# Plot the data\n",
    "for i, color in enumerate(colors):\n",
    "    cur_data = iris.data[iris.target == i]\n",
    "    plt.scatter(cur_data[:,0],\n",
    "                cur_data[:,1], \n",
    "                marker='o',\n",
    "                facecolors='none', \n",
    "                edgecolors='black', \n",
    "                s=40,\n",
    "                label=iris.target_names[i])\n",
    "\n",
    "    test_data = X_test[y_test == i]\n",
    "    plt.scatter(test_data[:,0], \n",
    "                test_data[:, 1],\n",
    "                marker='s',\n",
    "                facecolors='black',\n",
    "                edgecolors='black',\n",
    "                s=40,\n",
    "                label=iris.target_names[i])\n",
    "\n",
    "# Compute predictions for training and testing data\n",
    "y_train_pred = classifier.predict(X_train)\n",
    "accuracy_training = np.mean(y_train_pred.ravel() == y_train.ravel()) * 100\n",
    "print('Accuracy on training data = {}'.format(accuracy_training))\n",
    "\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "accuracy_training = np.mean(y_test_pred.ravel() == y_test.ravel()) * 100\n",
    "print('Accuracy on testing data = {}'.format(accuracy_testing))\n",
    "\n",
    "plt.title('GMM classifier')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
